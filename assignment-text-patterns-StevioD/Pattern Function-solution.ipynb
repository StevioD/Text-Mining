{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook holds the starting point for your Pattern Assignment. I'll put the function stub at the top, but I have some potentially helpful examples down below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from nltk.book import *\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "\n",
    "from pprint import pprint # get some prettier printing of objects\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patterns(text)  :\n",
    "    \"\"\"\n",
    "        This function takes text as an input and returns a dictionary of statistics,\n",
    "        after cleaning the text. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # We'll make things a big clearer by initializing the \n",
    "    # statistics here. These are placeholder values.\n",
    "    total_tokens = 1\n",
    "    unique_tokens = 0\n",
    "    avg_token_len = 0.0\n",
    "    lex_diversity = 0.0\n",
    "    top_10 = Counter()\n",
    "    \n",
    "    # Do your tokenization and normalization here\n",
    "    \n",
    "    beo_clean = [w for w in beowulf.split()]\n",
    "    beo_clean = [w.lower() for w in beo_clean if w.isalpha() and w not in sw]\n",
    "    #word_tokenize(beowulf)\n",
    "    #sent_tokenize(beowulf)\n",
    "    \n",
    "    # Calculate your statistics here\n",
    "    \n",
    "    print(f\"Beowulf is {len(beo_clean)} tokens long.\")\n",
    "    print(f\"Beowulf has {len(set(beo_clean))} unique tokens.\")\n",
    "\n",
    "    print(f\"Beowulf's lexical diversity is {len(set(beo_clean))/len(beo_clean):.3f}.\")\n",
    "\n",
    "    beo_token_len = [len(w) for w in beo_clean]\n",
    "\n",
    "    print(f\"Beowulf's average token length is {np.mean(beo_token_len):.2f}.\")\n",
    "\n",
    "    pprint(sorted(Counter(beo_token_len).items()))\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"All statistics are calculated after normalization and tokenization.\")\n",
    "    \n",
    "    # Now we'll fill out the dictionary. \n",
    "    results = {'tokens':total_tokens,\n",
    "               'unique_tokens':unique_tokens,\n",
    "               'avg_token_length':avg_token_len,\n",
    "               'lexical_diversity':lex_diversity,\n",
    "               'top_10':top_10}\n",
    "\n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "beowulf = open(\"beowulf.txt\",'r').read()\n",
    "big_word_file = open(\"big.txt\",'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beowulf is 10146 tokens long.\n",
      "Beowulf has 3033 unique tokens.\n",
      "Beowulf's lexical diversity is 0.299.\n",
      "Beowulf's average token length is 5.14.\n",
      "[(1, 205),\n",
      " (2, 251),\n",
      " (3, 1135),\n",
      " (4, 2719),\n",
      " (5, 2053),\n",
      " (6, 1540),\n",
      " (7, 1060),\n",
      " (8, 725),\n",
      " (9, 285),\n",
      " (10, 100),\n",
      " (11, 51),\n",
      " (12, 16),\n",
      " (13, 3),\n",
      " (14, 1),\n",
      " (15, 2)]\n",
      "\n",
      "All statistics are calculated after normalization and tokenization.\n",
      "Beowulf is 10146 tokens long.\n",
      "Beowulf has 3033 unique tokens.\n",
      "Beowulf's lexical diversity is 0.299.\n",
      "Beowulf's average token length is 5.14.\n",
      "[(1, 205),\n",
      " (2, 251),\n",
      " (3, 1135),\n",
      " (4, 2719),\n",
      " (5, 2053),\n",
      " (6, 1540),\n",
      " (7, 1060),\n",
      " (8, 725),\n",
      " (9, 285),\n",
      " (10, 100),\n",
      " (11, 51),\n",
      " (12, 16),\n",
      " (13, 3),\n",
      " (14, 1),\n",
      " (15, 2)]\n",
      "\n",
      "All statistics are calculated after normalization and tokenization.\n"
     ]
    }
   ],
   "source": [
    "beo_results = get_patterns(beowulf)\n",
    "big_results = get_patterns(big_word_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you've finished the assignment, these next cells should run without raising any assertion errors. It's always possible that _I_ have a mistake in my version, so if you think you've done everything correctly and you're still getting errors, let me know. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-de8b93a852d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeo_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m9288\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeo_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unique_tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2970\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.31\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbeo_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lexical_diversity'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5.3\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbeo_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_token_length'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m5.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeo_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'top_10'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert(beo_results['tokens']==9288)\n",
    "assert(beo_results['unique_tokens']==2970)\n",
    "assert(0.31 < beo_results['lexical_diversity'] < 0.32)\n",
    "assert(5.3 < beo_results['avg_token_length'] < 5.4)\n",
    "assert(len(beo_results['top_10'])==10)\n",
    "assert(beo_results['top_10'][4]==('thou',47))\n",
    "print(\"Passed all assertion tests.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1a96b2efe0d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbig_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m410950\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbig_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unique_tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m25173\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.06\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbig_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lexical_diversity'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.065\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6.3\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbig_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_token_length'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m6.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbig_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'top_10_tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert(big_results['tokens']==410950)\n",
    "assert(big_results['unique_tokens']==25173)\n",
    "assert(0.06 < big_results['lexical_diversity'] < 0.065)\n",
    "assert(6.3 < big_results['avg_token_length'] < 6.4)\n",
    "assert(len(big_results['top_10_tokens'])==10)\n",
    "assert(big_results['top_10'][0]==('said',2946))\n",
    "assert(big_results['top_10'][8]==('upon',1088))\n",
    "print(\"Passed all assertion tests.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "All of the important bits of the assignment are above here. Everything below is designed to help you wrap your mind around what I'm asking for. \n",
    "\n",
    "\n",
    "### Dictionaries\n",
    "\n",
    "We'll talk about dictionary objects in class a bit, but think of them as a big bag of key-value pairs. The keys, which have to be unique, are like an address to the data that's being stored in the \"value\", which can be any kind of object. They're incredibly versatile and useful objects to learn about. Here's a [video](https://www.youtube.com/watch?v=daefaLgNkw0) that will help orient you to them. \n",
    "\n",
    "In the next couple of cells, I'll make a couple of dictionaries and show you some basic functionality with them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animal_weights = {\"mouse\":0.03,\"dog\":20,\"horse\":700,\"elephant\":4100,\"blue whale\":100000}\n",
    "\n",
    "animal_weights['dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mouse\n",
      "0.03\n",
      "dog\n",
      "20\n",
      "horse\n",
      "700\n",
      "elephant\n",
      "4100\n",
      "blue whale\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "for key in animal_weights :\n",
    "    print(key)\n",
    "    print(animal_weights[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-9852ec48d2b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This will throw an error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0manimal_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'cat'"
     ]
    }
   ],
   "source": [
    "# This will throw an error\n",
    "animal_weights['cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mouse': 0.03,\n",
       " 'dog': 20,\n",
       " 'horse': 700,\n",
       " 'elephant': 4100,\n",
       " 'blue whale': 100000,\n",
       " 'cat': 3}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animal_weights['cat'] = 3\n",
    "\n",
    "animal_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An average mouse weighs 0.03 kilograms (0.01 lbs).\n",
      "An average dog weighs 20 kilograms (9.09 lbs).\n",
      "An average horse weighs 700 kilograms (318.18 lbs).\n",
      "An average elephant weighs 4100 kilograms (1863.64 lbs).\n",
      "An average blue whale weighs 100000 kilograms (45454.55 lbs).\n",
      "An average cat weighs 3 kilograms (1.36 lbs).\n"
     ]
    }
   ],
   "source": [
    "for animal, wt in animal_weights.items() :\n",
    "    print(f\"An average {animal} weighs {wt} kilograms ({wt/2.2:0.2f} lbs).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "\n",
    "Functions are a useful way to organize code and prevent yourself from making mistakes. There is a lot to learn about functions, but we'll just handle the basics here. Functions are declared with the `def` statement (for \"define\", I assume). The parentheses allow you to define the _parameters_ that are passed into the function. Here's a simple example that squares a number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_square(x) :\n",
    "    return(x*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_square(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10404"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_square(102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-df6287600777>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msimple_square\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-3ae6d6fb4cd0>\u001b[0m in \u001b[0;36msimple_square\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msimple_square\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'str'"
     ]
    }
   ],
   "source": [
    "simple_square(\"cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add some error handling to make sure we only try to square a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x) :\n",
    "    if not str(x).isnumeric() :\n",
    "        raise ValueError(f\"Hey, {x} isn't a number!\")\n",
    "    else :\n",
    "        return(x*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Hey, cat isn't a number!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-214d63535043>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-e00ab8d37a8e>\u001b[0m in \u001b[0;36msquare\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnumeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Hey, {x} isn't a number!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Hey, cat isn't a number!"
     ]
    }
   ],
   "source": [
    "square(\"cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of a function that returns a dictionary based on an NLTK text being sent in. (Note that those texts are in lists.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text) :\n",
    "    # Take in a text, return the first token, the 100th token, and the last token.\n",
    "    \n",
    "    first_token = text[0]\n",
    "    hundredth_token = text[99]\n",
    "    last_token = text[-1]\n",
    "    \n",
    "    ret_dict = {'first':first_token,\n",
    "                '100th':hundredth_token,\n",
    "                'last':last_token}\n",
    "    return(ret_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first': '[', '100th': ',', 'last': '.'}\n",
      "{'first': 'now', '100th': 'JOIN', 'last': '.'}\n",
      "{'first': '25', '100th': 'groomed', 'last': '!'}\n"
     ]
    }
   ],
   "source": [
    "print(process_text(text1))\n",
    "print(process_text(text5))\n",
    "print(process_text(text8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
