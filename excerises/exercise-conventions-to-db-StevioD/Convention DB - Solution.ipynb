{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convention Database\n",
    "\n",
    "In this notebook we store our convention data in a database. See the README for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sqlite3\n",
    "import os\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_files = \"C:/users/jchan/dropbox/teaching/outsidedata/2020Conventions/\"\n",
    "transcript_files = os.listdir(path_to_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by creating a lookup between the files and the nights/parties. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just going to be a two-item list with party and night.\n",
    "lookup_party_night = defaultdict(list)\n",
    "\n",
    "file_night = re.compile(r\"night-[1-4]\")\n",
    "\n",
    "for file in transcript_files :\n",
    "    if \"rnc\" in file :\n",
    "        lookup_party_night[file].append(\"Republican\")\n",
    "    elif \"dnc\" in file : \n",
    "        lookup_party_night[file].append(\"Democratic\")\n",
    "        \n",
    "    night_text = file_night.search(file).group(0)    \n",
    "    lookup_party_night[file].append(night_text.split(\"-\")[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's set up our DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "cur = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('''DROP TABLE IF EXISTS conventions''')\n",
    "cur.execute('''CREATE TABLE conventions (\n",
    "    party TEXT, \n",
    "    night INTEGER, \n",
    "    speaker TEXT,\n",
    "    speaker_count INTEGER,\n",
    "    time TEXT, \n",
    "    text TEXT,\n",
    "    text_len TEXT, \n",
    "    file TEXT)''')\n",
    "\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that was easy enough. Now the tough part. We're going to need to use a regular expression to match the speaker, split the text on that, and funnel everything into the right spot. We wrapped the text, so we'll clean returns out of the text as we put it in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_time_pattern = re.compile(r\"[-|.|?|)]\\s[a-zA-Z0-9 \\n'-]*:\\s\\(\\s\\d*:?\\d*:\\d*\\s\\)\")\n",
    "#time_pattern = re.compile(r\"\\s\\(\\s\\d*:?\\d*:\\d*\\s\\)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_speakers(speaker) : \n",
    "    # Missing punctuation causes our process to fail. We could engineer a solution, \n",
    "    # by doing multiple passes and removing speakers from text, but that could\n",
    "    # be fraught too. We'll just fix things manually and not worry about the \n",
    "    # textual errors. \n",
    "    # \n",
    "    # One issue is there are a handful of cases where the closing puctuation is a\n",
    "    # dash. This also occurs in hyphenated names, so the fix to the regex would \n",
    "    # be kind of a hassle. Seemed easier to do the lookup.\n",
    "    # \n",
    "    # Note this pretty handy way to do these fixes. \n",
    "\n",
    "    fix_lu = {   \n",
    "        'Will we see to it that no one who works full time can live in poverty Pete Buttigieg':'Pete Buttigieg',\n",
    "        'I stayed for an hour and a half- Jamie Ponder':'Jamie Ponder',\n",
    "        'It seems like just yesterday that we were at our first convention- Melania Trump':'Melania Trump',\n",
    "        'The night before I fought back- Kayleigh McEnany':'Kayleigh McEnany',\n",
    "        'It is a sad irony that Jackie immigrated- Speaker 8':'Speaker 8',\n",
    "        'I withdrew from the terrible one- Donald Trump':'Donald Trump',\n",
    "        'Alaska casts seven votes for Bernie- Chuck Degnan':'Chuck Degnan',\n",
    "        'A lot of us were shocked and I think what gives me hope- Art Acevedo':'Art Acevedo',\n",
    "        'But Joe Biden is a guy who has earned the respect- Eva Longoria':'Eva Longoria',\n",
    "        'And the promise of our country led by president Joe Biden and vice-president Kamala Harris Kerry Washington':'Kerry Washington',\n",
    "        'Joe will also- Senator Bernie Sanders':'Senator Bernie Sanders'\n",
    "    }\n",
    "\n",
    "    if speaker in fix_lu : \n",
    "        return(fix_lu[speaker])\n",
    "    else : \n",
    "        return(speaker)\n",
    "    \n",
    "\n",
    "\n",
    "def parse_speakers_times(st_items) :\n",
    "    # Since we'll need to split these carefully, let's\n",
    "    # write a function to just split one of them. They come in \n",
    "    # like '. Name Name: ( HH:MM:SS )' with unknown first punctuation\n",
    "    # And complicated names. We'll return three lists in a dictionary\n",
    "    # with keys \"speakers\", \"times\", \"last_puncts\" holding the \n",
    "    # speakers, the times, and the closing punctuation, since \n",
    "    # that needs to be glued onto the text. \n",
    "    \n",
    "    time_clean = re.compile(r\"\\s\\(\\s|\\s\\)\")\n",
    "    \n",
    "    speakers = []\n",
    "    times = []\n",
    "    last_puncts = []\n",
    "    \n",
    "    # There are probably some more efficient ways to do \n",
    "    # what I'm doing in this loop. \n",
    "    for st_item in st_items : \n",
    "        last_puncts.append(st_item[0])\n",
    "        pieces = st_item[1:].split(\":\")\n",
    "        \n",
    "        speakers.append(pieces[0].strip().replace(\"\\n\",\" \"))\n",
    "        \n",
    "        # This one took a while to get right\n",
    "        this_time = \":\".join([time_clean.sub(\"\",piece) for piece in pieces[1:]])     \n",
    "\n",
    "        times.append(this_time)\n",
    "        \n",
    "    speakers = list(map(fix_speakers,speakers))\n",
    "        \n",
    "    assert(len(speakers)==len(times))\n",
    "    assert(len(speakers)==len(last_puncts))\n",
    "        \n",
    "    return({'speakers':speakers,\n",
    "            'times':times,\n",
    "            'last_puncts':last_puncts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in transcript_files : \n",
    "    with open(path_to_files + file,encoding=\"UTF-8\") as infile :\n",
    "        file_text = infile.read()\n",
    "\n",
    "        # This command will give us all the matches\n",
    "        speakers_times = speaker_time_pattern.findall(file_text)\n",
    "\n",
    "        # And this one will split the file\n",
    "        split_texts = speaker_time_pattern.split(file_text)\n",
    "\n",
    "        # First bit of text is unattributed. Keeping the\n",
    "        # formatting the same\n",
    "\n",
    "        speakers_times = ['. Unknown: ( 00:00 )'] + speakers_times\n",
    "\n",
    "        # Do the parsing in a function\n",
    "        results = parse_speakers_times(speakers_times)\n",
    "\n",
    "        # The last mark of punctuation from text N was \n",
    "        # caught in the Speaker in the N+1 position. let's fix that. \n",
    "        texts = [split_texts[idx] + results['last_puncts'][idx] for idx in range(len(split_texts))]\n",
    "\n",
    "        # A little cleaning of the texts\n",
    "        texts = [t.strip().replace(\"\\n\",\" \") for t in texts]\n",
    "\n",
    "        # All we need now is a counter to keep track of how many times this speaker has \n",
    "        # spoken on this night. \n",
    "        speaker_counter = defaultdict(int)\n",
    "\n",
    "        assert(len(results['speakers'])==len(texts))\n",
    "        \n",
    "        for idx in range(len(texts)) : \n",
    "            this_speaker = results['speakers'][idx]\n",
    "\n",
    "            # I used lines like this to discover errors in the speakers\n",
    "            if len(this_speaker) > 30 : \n",
    "                print(f\"'{this_speaker}':'change',\")\n",
    "\n",
    "            speaker_counter[this_speaker] += 1\n",
    "\n",
    "            db_row = (lookup_party_night[file][0],\n",
    "                      lookup_party_night[file][1],\n",
    "                      this_speaker,\n",
    "                      speaker_counter[this_speaker],\n",
    "                      results['times'][idx],\n",
    "                      texts[idx],\n",
    "                      len(texts[idx].split()),\n",
    "                      file)\n",
    "\n",
    "            cur.execute('''INSERT INTO conventions\n",
    "                                (party,night,speaker,speaker_count,\n",
    "                                time,text,text_len,file) \n",
    "                           VALUES (?,?,?,?,?,?,?,?)''',\n",
    "                       db_row) \n",
    "\n",
    "    # Might as well commit each file\n",
    "    db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run some queries and see how things look\n",
    "for row in cur.execute('''\n",
    "        SELECT party, sum(text_len) as words\n",
    "        FROM conventions\n",
    "        GROUP BY party\n",
    "        ORDER BY words DESC\n",
    "''') : \n",
    "    print(f\"The {row[0]} party had {row[1]} words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in cur.execute('''\n",
    "        SELECT party, speaker, sum(text_len) as words\n",
    "        FROM conventions\n",
    "        GROUP BY party, speaker\n",
    "        ORDER BY words DESC\n",
    "        LIMIT 50\n",
    "''') : \n",
    "    print(f\"For the {row[0]} party, {row[1]} said {row[2]} words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in cur.execute('''\n",
    "        SELECT party, night, sum(text_len) as words\n",
    "        FROM conventions\n",
    "        GROUP BY party, night\n",
    "        ORDER BY words DESC\n",
    "''') : \n",
    "    print(f\"The {row[0]} party on night {row[1]} said {row[2]} words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
